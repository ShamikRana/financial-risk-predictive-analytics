{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictive Analytics for Credit Default\n",
        "\n",
        "**Objective:** Build a clean, reproducible notebook that performs Exploratory Data Analysis (EDA), Feature Engineering, and Model Training for predicting credit-card default. This notebook is formatted for submission to an MSc Data Science professor.\n",
        "\n",
        "**Notes for reviewer:**\n",
        "- The dataset should be placed locally and the path updated in the `DATA_PATH` variable.\n",
        "- The notebook focuses only on EDA, feature engineering, and model training with clear, reproducible steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Install any missing packages before running (run in a terminal or notebook cell):\n",
        "```\n",
        "pip install pandas numpy matplotlib seaborn scikit-learn lightgbm joblib\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
        "    classification_report, confusion_matrix, brier_score_loss\n",
        ")\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (9,6)\n",
        "\n",
        "RND = 42\n",
        "os.makedirs('models', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading & Quick Checks\n",
        "\n",
        "Update `DATA_PATH` to point at your local CSV. The notebook assumes the UCI Credit Card dataset with column `default.payment.next.month`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Path to your CSV - update if needed\n",
        "DATA_PATH = r\"D:\\Data Science\\financial-risk-predictive-analytics\\UCI_Credit_Card.csv\"\n",
        "\n",
        "assert os.path.exists(DATA_PATH), f\"Data file not found at {DATA_PATH}. Please update DATA_PATH.\"\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df = df.rename(columns={\"default.payment.next.month\": \"default\"})\n",
        "if 'ID' in df.columns:\n",
        "    df = df.drop(columns=['ID'])\n",
        "\n",
        "print('Shape:', df.shape)\n",
        "display(df.head())\n",
        "print('\\nColumn dtypes:')\n",
        "display(df.dtypes.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data quality checks\n",
        "- Look for missing values\n    - Dataset should not contain missing values by design; if there are any, we handle them conservatively later.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "missing = df.isnull().sum()\n",
        "missing[missing>0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Target distribution and class balance\n",
        "Understanding class balance is important for metric selection and modeling choices.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "target_counts = df['default'].value_counts().sort_index()\n",
        "target_pct = df['default'].value_counts(normalize=True).sort_index() * 100\n",
        "display(pd.DataFrame({'count': target_counts, 'percentage': target_pct.round(2)}))\n",
        "\n",
        "sns.countplot(x='default', data=df)\n",
        "plt.title('Target Distribution (Non-default=0 vs Default=1)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Categorical value validation\n",
        "Some categorical codes in the original dataset include undocumented values (e.g., EDUCATION=0,5,6 or MARRIAGE=0). Consolidate them into a single 'Other' code for stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Consolidate undocumented categories\n",
        "df['EDUCATION'] = df['EDUCATION'].replace({0:4, 5:4, 6:4})\n",
        "df['MARRIAGE'] = df['MARRIAGE'].replace({0:3})\n",
        "\n",
        "display(df[['EDUCATION','MARRIAGE']].apply(pd.Series.value_counts))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Distribution inspection (key numeric features)\n",
        "Plot distributions for `LIMIT_BAL` and `AGE` to inspect skewness and outliers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_distribution(col, bins=40):\n",
        "    sns.histplot(df[col], bins=bins, kde=True, stat='density')\n",
        "    plt.title(f\"{col} | skew={df[col].skew():.2f}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Density')\n",
        "    plt.show()\n",
        "\n",
        "for col in ['LIMIT_BAL','AGE']:\n",
        "    plot_distribution(col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Delinquency features & business-focused engineered variables\n",
        "Create aggregated features that are interpretable and predictive:\n",
        "- `num_delayed_payments`: count of months with PAY_*>0\n",
        "- `ever_late`: binary flag if customer was late in any month\n",
        "- `total_bill_amt`, `total_pay_amt`\n",
        "- `payment_ratio` and `credit_utilization`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pay_cols = [c for c in df.columns if c.startswith('PAY_') and c not in ('PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6')]\n",
        "bill_cols = [c for c in df.columns if c.startswith('BILL_AMT')]\n",
        "pay_amt_cols = [c for c in df.columns if c.startswith('PAY_AMT')]\n",
        "\n",
        "df['num_delayed_payments'] = (df[pay_cols] > 0).sum(axis=1)\n",
        "df['ever_late'] = (df[pay_cols] > 0).any(axis=1).astype(int)\n",
        "\n",
        "df['total_bill_amt'] = df[bill_cols].sum(axis=1)\n",
        "df['total_pay_amt'] = df[pay_amt_cols].sum(axis=1)\n",
        "\n",
        "df['payment_ratio'] = df['total_pay_amt'] / (df['total_bill_amt'] + 1)\n",
        "df['credit_utilization'] = df['total_bill_amt'] / (df['LIMIT_BAL'] + 1)\n",
        "\n",
        "sns.boxplot(x='default', y='num_delayed_payments', data=df)\n",
        "plt.title('Number of Delayed Payments vs Default')\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='default', y='payment_ratio', data=df)\n",
        "plt.ylim(0,3)\n",
        "plt.title('Payment Ratio vs Default')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Recent behavior features\n",
        "Recent months are typically more predictive; compute mean of last 3 months for bills/payments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['recent_bill_mean'] = df[['BILL_AMT1','BILL_AMT2','BILL_AMT3']].mean(axis=1)\n",
        "df['recent_pay_mean'] = df[['PAY_AMT1','PAY_AMT2','PAY_AMT3']].mean(axis=1)\n",
        "\n",
        "display(df[['recent_bill_mean','recent_pay_mean']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Correlation analysis (heatmap)\n",
        "Inspect correlations to find strong linear relationships and potential multicollinearity (helpful for linear models and interpretation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "sns.heatmap(df.corr(), cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Feature relevance estimation\n",
        "Estimate linear (point-biserial) and non-linear (mutual information) relationships with target.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Point-biserial correlation\n",
        "num_features = df.select_dtypes(include=[np.number]).columns.drop('default')\n",
        "pb = {col: stats.pointbiserialr(df['default'], df[col]).correlation for col in num_features}\n",
        "pb = pd.Series(pb).sort_values(key=lambda x: x.abs(), ascending=False)\n",
        "display(pb.head(20))\n",
        "\n",
        "# Mutual information (needs encoding for categorical variables)\n",
        "df_mi = df.copy()\n",
        "for c in df_mi.select_dtypes(include=['object','category']).columns:\n",
        "    df_mi[c] = LabelEncoder().fit_transform(df_mi[c].astype(str))\n",
        "\n",
        "mi = pd.Series(\n",
        "    mutual_info_classif(df_mi.drop(columns=['default']), df_mi['default'], random_state=RND),\n",
        "    index=df_mi.drop(columns=['default']).columns\n",
        ").sort_values(ascending=False)\n",
        "display(mi.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Final feature selection for modeling\n",
        "Build a compact, interpretable feature set suitable for API deployment and model auditing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "selected_features = [\n",
        "    'LIMIT_BAL', 'total_bill_amt', 'total_pay_amt', 'payment_ratio',\n",
        "    'credit_utilization', 'num_delayed_payments', 'ever_late',\n",
        "    'AGE', 'SEX', 'EDUCATION', 'MARRIAGE', 'recent_bill_mean'\n",
        "]\n",
        "final_features = [f for f in selected_features if f in df.columns]\n",
        "missing_feats = set(selected_features) - set(final_features)\n",
        "if missing_feats:\n",
        "    print('Warning: missing features will be excluded:', missing_feats)\n",
        "\n",
        "final_df = df[final_features].copy()\n",
        "\n",
        "# Conservative imputation and dtype normalization\n",
        "num_cols = final_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = final_df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "\n",
        "for c in num_cols:\n",
        "    final_df[c] = final_df[c].fillna(final_df[c].median())\n",
        "for c in cat_cols:\n",
        "    if final_df[c].isnull().any():\n",
        "        final_df[c] = final_df[c].fillna(final_df[c].mode().iloc[0])\n",
        "\n",
        "for c in ['SEX','EDUCATION','MARRIAGE']:\n",
        "    if c in final_df.columns:\n",
        "        final_df[c] = final_df[c].astype('category')\n",
        "\n",
        "print('final_df shape:', final_df.shape)\n",
        "display(final_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Train/Test split\n",
        "Perform a stratified split to preserve class balance between train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = final_df.copy()\n",
        "y = df['default'].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=RND\n",
        ")\n",
        "print('Train:', X_train.shape, 'Test:', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Preprocessing pipelines & Models\n",
        "Construct numeric and categorical transformers and define three model pipelines: Logistic Regression, Random Forest, LightGBM.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_features = X.select_dtypes(include=['category','object']).columns.tolist()\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "cat_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', cat_transformer, cat_features)\n",
        "], remainder='drop')\n",
        "\n",
        "logreg_pipe = Pipeline([('pre', preprocessor), ('clf', LogisticRegression(solver='saga', max_iter=5000, random_state=RND))])\n",
        "rf_pipe = Pipeline([('pre', preprocessor), ('clf', RandomForestClassifier(n_jobs=-1, random_state=RND))])\n",
        "lgb_pipe = Pipeline([('pre', preprocessor), ('clf', lgb.LGBMClassifier(random_state=RND, n_jobs=-1))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Hyperparameter search setup (RandomizedSearchCV)\n",
        "Use `roc_auc` as the primary scoring metric. `n_iter` kept moderate for speed in a classroom setting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "param_dist = {\n",
        "    'logreg': {\n",
        "        'clf__penalty': ['l2','l1'],\n",
        "        'clf__C': uniform(loc=0.01, scale=10.0),\n",
        "        'clf__class_weight': [None, 'balanced']\n",
        "    },\n",
        "    'rf': {\n",
        "        'clf__n_estimators': randint(100, 400),\n",
        "        'clf__max_depth': [None, 5, 10, 20],\n",
        "        'clf__min_samples_split': randint(2, 8),\n",
        "        'clf__max_features': ['sqrt','log2', 0.5, None],\n",
        "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
        "    },\n",
        "    'lgb': {\n",
        "        'clf__n_estimators': randint(100, 400),\n",
        "        'clf__num_leaves': randint(16, 128),\n",
        "        'clf__learning_rate': uniform(loc=0.01, scale=0.3),\n",
        "        'clf__max_depth': [-1, 3, 6, 12],\n",
        "        'clf__subsample': uniform(loc=0.6, scale=0.4)\n",
        "    }\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=RND)\n",
        "n_iter = 24\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def tune_model(pipe, params, X, y, cv, n_iter=24, scoring='roc_auc'):\n",
        "    rs = RandomizedSearchCV(pipe, params, n_iter=n_iter, cv=cv, scoring=scoring,\n",
        "                            random_state=RND, n_jobs=-1, verbose=1, return_train_score=False)\n",
        "    rs.fit(X, y)\n",
        "    print('Best score (cv):', rs.best_score_)\n",
        "    print('Best params:', rs.best_params_)\n",
        "    return rs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 13.1 Tune and save models\n",
        "We run a shorter search for classroom speed. In a production or thesis run you may increase `n_iter` and `cv` folds.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Tuning Logistic Regression...')\n",
        "rs_log = tune_model(logreg_pipe, param_dist['logreg'], X_train, y_train, cv=cv, n_iter=20)\n",
        "best_log = rs_log.best_estimator_\n",
        "joblib.dump(best_log, 'models/logreg_pipeline.joblib')\n",
        "\n",
        "print('\\nTuning Random Forest...')\n",
        "rs_rf = tune_model(rf_pipe, param_dist['rf'], X_train, y_train, cv=cv, n_iter=24)\n",
        "best_rf = rs_rf.best_estimator_\n",
        "joblib.dump(best_rf, 'models/rf_pipeline.joblib')\n",
        "\n",
        "print('\\nTuning LightGBM...')\n",
        "scale_pos_weight = (y_train==0).sum() / (y_train==1).sum()\n",
        "param_dist_lgb = param_dist['lgb'].copy()\n",
        "param_dist_lgb['clf__scale_pos_weight'] = [scale_pos_weight, None]\n",
        "rs_lgb = tune_model(lgb_pipe, param_dist_lgb, X_train, y_train, cv=cv, n_iter=24)\n",
        "best_lgb = rs_lgb.best_estimator_\n",
        "joblib.dump(best_lgb, 'models/lgbm_pipeline.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Evaluation on hold-out test set\n",
        "Compute ROC-AUC, PR-AUC, classification report, confusion matrix, and plot ROC & PR curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "models = {'LogisticRegression': best_log, 'RandomForest': best_rf, 'LightGBM': best_lgb}\n",
        "results = {}\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for name, model in models.items():\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "    y_pred = model.predict(X_test)\n",
        "    roc = roc_auc_score(y_test, y_prob)\n",
        "    pr = average_precision_score(y_test, y_prob)\n",
        "    results[name] = {'roc_auc': float(roc), 'pr_auc': float(pr)}\n",
        "    print(f\"--- {name} ---\")\n",
        "    print('ROC-AUC:', roc)\n",
        "    print('PR-AUC:', pr)\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc:.3f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves - Test Set')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for name, model in models.items():\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "    ap = average_precision_score(y_test, y_prob)\n",
        "    plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curves - Test Set')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calibration plots\n",
        "from sklearn.calibration import calibration_curve\n",
        "plt.figure(figsize=(12,4))\n",
        "for i, (name, model) in enumerate(models.items(), 1):\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "    prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
        "    plt.subplot(1,3,i)\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label=name)\n",
        "    plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
        "    plt.xlabel('Mean predicted prob')\n",
        "    plt.ylabel('Fraction of positives')\n",
        "    plt.title(f\"{name} (Brier={brier_score_loss(y_test, y_prob):.4f})\")\n",
        "    plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save results summary\n",
        "with open('models/results_summary.json','w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print('Saved models and results in ./models/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Conclusion & next steps (for thesis / production)\n",
        "- Random forest / LightGBM often outperform simple logistic regression on this dataset (check ROC/PR metrics above).\n",
        "- Next steps: feature importance analysis, SHAP explanations for model interpretability, stronger hyperparameter tuning, cross-validation across multiple random seeds, and productionization (model card, API, monitoring).\n",
        "- Ensure reproducibility: pin package versions and include a `requirements.txt` in your GitHub repo.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}